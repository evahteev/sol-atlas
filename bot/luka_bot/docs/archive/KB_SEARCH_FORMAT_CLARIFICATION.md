# KB Search Output Format Clarification

**Date**: 2025-10-11  
**Status**: âœ… Clarified

## Expected Output Format

When users ask about past conversations, the bot should provide:

1. **LLM Summary** (1-2 sentences) - Brief, conversational summary
2. **Separator Line** - Visual break
3. **Message Snippets** - Formatted cards with links

### Example Output Structure

```
User: "@GuruKeeperBot What did we discuss about deployment?"

Bot Response:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Found several discussions about         â”‚  â† LLM SUMMARY (main LLM)
â”‚ deployment strategies:                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                    â”‚  â† SEPARATOR
â”‚ ğŸ“š Found 3 relevant message(s):         â”‚  â† TOOL OUTPUT (search_knowledge_base)
â”‚                                         â”‚
â”‚ 1. ğŸ‘¤ Alice â€¢ ğŸ‘¥ Group â€¢ 2025-10-11    â”‚
â”‚    ğŸ”— View in group                     â”‚
â”‚    ğŸ’¬ "We should deploy using Docker..." â”‚
â”‚                                         â”‚
â”‚ 2. ğŸ‘¤ Bob â€¢ ğŸ‘¥ Group â€¢ 2025-10-10      â”‚
â”‚    ğŸ”— View in group                     â”‚
â”‚    ğŸ’¬ "Kubernetes would be better..."   â”‚
â”‚                                         â”‚
â”‚ 3. ğŸ‘¤ Carol â€¢ ğŸ‘¥ Group â€¢ 2025-10-09    â”‚
â”‚    ğŸ”— View in group                     â”‚
â”‚    ğŸ’¬ "Let's discuss deployment at..."  â”‚
â”‚                                         â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## How It Works

### 1. LLM Summary (Main LLM - GPT-4)

**Generated by**: The main conversational LLM  
**Purpose**: Provide context and introduce the search results  
**Format**: 1-2 conversational sentences  

**Examples**:
- English: "Found several discussions about X:"
- Russian: "ĞĞ°ÑˆÑ‘Ğ» Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ±ÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾ X:"

**Instructions to LLM**:
```
Provide a BRIEF 1-2 sentence summary introducing the search results.
Be conversational and natural. Keep it SHORT.
```

### 2. Tool Output (search_knowledge_base)

**Generated by**: The KB search tool  
**Purpose**: Show actual messages with clickable links  
**Format**: Structured message cards  

**Contains**:
- Separator lines (`â”â”â”â”â”â”`)
- Result count header
- Individual message cards:
  - Sender emoji and name (ğŸ‘¤ User / ğŸ¤– Bot)
  - Source indicator (ğŸ‘¥ Group / ğŸ‘¤ DM)
  - Date/time
  - Clickable deeplink (ğŸ”— View in group)
  - Message preview (truncated to ~150 chars)

## Code Flow

### Step 1: User Asks Question
```
User: "@GuruKeeperBot What did we discuss about X?"
```

### Step 2: Main LLM Decides to Use Tool
```
System Prompt: "You MUST use search_knowledge_base when users ask about past conversations"
LLM: "I need to search the knowledge base for this"
```

### Step 3: LLM Generates Response WITH Tool Call
```python
# LLM's response includes:
- Text part: "Found several discussions about X:"
- Tool call: search_knowledge_base(query="X")
```

### Step 4: Tool Executes and Returns Formatted Snippets
```python
# search_knowledge_base returns:
"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“š Found 3 relevant message(s):

1. ğŸ‘¤ User â€¢ ğŸ‘¥ Group â€¢ Date
   ğŸ”— View in group
   ğŸ’¬ "Message preview..."

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
```

### Step 5: Streaming Service Combines Output
```python
# llm_service.py combines:
full_response = llm_text + tool_output

# Result:
"Found several discussions about X:

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“š Found 3 relevant message(s):

1. Message card...
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
```

### Step 6: Display to User
```python
# group_messages.py checks if KB snippets exist
has_kb_snippets = 'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”' in full_response
if has_kb_snippets:
    # Don't escape HTML - preserve clickable links
    formatted_response = full_response
else:
    formatted_response = escape_html(full_response)

await message.reply(formatted_response, parse_mode="HTML")
```

## Important Notes

### What the Tool Does NOT Do

The `search_knowledge_base` tool does **NOT**:
- âŒ Generate AI summaries internally
- âŒ Try to explain what was found
- âŒ Provide context or narrative

It **ONLY** returns:
- âœ… Formatted message cards
- âœ… Clickable deeplinks
- âœ… Structured data

### What the Main LLM Does

The main LLM (GPT-4):
- âœ… Provides conversational context
- âœ… Generates the summary
- âœ… Calls the tool when needed
- âœ… Introduces the results naturally

### Removed Code

Removed unused internal summary generation (`_generate_kb_summary`):
- Was generating summaries but never using them
- Created unnecessary LLM calls
- Main LLM's summary is better and more contextual

## System Prompt Instructions

Clear instructions to the LLM:

```
**How to use search_knowledge_base:**

1. First, provide your BRIEF 1-2 sentence summary
   Example: "Found several discussions about X:"

2. Then call search_knowledge_base(query="X")

3. The tool returns formatted message cards with links

4. Do NOT reformat the results - they're already formatted

5. Your summary appears first, tool output below

**Example flow:**
User: "What did we discuss?"
You: "Found several discussions:" [tool outputs formatted cards below]
```

## Testing

To verify correct format:

1. Ask: `@BotName What did we discuss about X?`

2. Expected response:
   ```
   [1-2 sentence summary]
   
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ğŸ“š Found N message(s):
   
   1. Message card...
   2. Message card...
   
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ```

3. Verify:
   - âœ… Summary is brief and natural
   - âœ… Links are clickable (not plain text)
   - âœ… Only original messages shown (no bot summaries)
   - âœ… Consistent formatting

## Files Modified

1. `/Users/evgenyvakhteev/Documents/src/dexguru/bot/luka_bot/agents/tools/knowledge_base_tools.py`
   - Removed unused `_generate_kb_summary` code reference
   - Clarified comments about tool responsibility
   - Enhanced system prompt with example flow

## Related Documentation

- `KB_SEARCH_FINAL_FIXES.md` - HTML links & bot filtering
- `KB_TOOL_EMPHASIS_UPDATE.md` - Tool usage emphasis
- `KB_SNIPPET_AUTO_APPEND.md` - Append mechanism

---

**Summary**: The format is correct - LLM provides summary, tool provides formatted snippets. Removed unused internal summary generation for clarity.

